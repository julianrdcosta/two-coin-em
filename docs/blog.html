<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>The Simplest Explanation of Expectation-Maximization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="blog_files/libs/clipboard/clipboard.min.js"></script>
<script src="blog_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="blog_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="blog_files/libs/quarto-html/popper.min.js"></script>
<script src="blog_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="blog_files/libs/quarto-html/anchor.min.js"></script>
<link href="blog_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="blog_files/libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="blog_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="blog_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="blog_files/libs/bootstrap/bootstrap-81267100e462c21b3d6c0d5bf76a3417.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Simplest Explanation of Expectation-Maximization</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Expectation-Maximization is a classic ML algorithm that is used to build a model of some process that involves hidden variables that aren’t observed in the data. Specifically, once we have a particular model set up, Expectation-Maximization lets us find settings of the model parameters that maximize the likelihood of the data.</p>
<p>It’s a rather subtle algorithm, which makes it all the more annoying that it’s usually introduced in the context of Gaussian mixture models, which are a particular kind of hidden variable model. Gaussian mixture models have a bunch of parameters to think about, which obviously blows up your working memory capacity, and leaves nothing left to understand EM.</p>
<p>Here’s an explanation of EM that I think is as simple as possible but no simpler.</p>
<p>Prerequisites: This post assumes that you know what the maximum likelihood estimate of a statistical model parameter is.</p>
<section id="the-two-coin-problem" class="level1">
<h1>The Two-Coin Problem</h1>
<p>Suppose we have two biased coins, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, with unknown head probabilities <span class="math inline">\(\theta_A\)</span> and <span class="math inline">\(\theta_B\)</span>. We conduct <span class="math inline">\(n\)</span> trials. In each trial <span class="math inline">\(i\)</span>, we flip one of the coins (chosen with equal probability) <span class="math inline">\(m_i\)</span> times and observe <span class="math inline">\(x_i\)</span> heads. However, we do not know which coin was used in each trial - maybe they were drawn out of a bag.</p>
<p>Specifically, suppose we conduct <span class="math inline">\(n=2\)</span> trials with the following observations:</p>
<ul>
<li><p>Trial <span class="math inline">\(1\)</span>: <span class="math inline">\(m_1=10\)</span> flips, <span class="math inline">\(x_1=2\)</span> heads</p></li>
<li><p>Trial <span class="math inline">\(2\)</span>: <span class="math inline">\(m_2=10\)</span> flips, <span class="math inline">\(x_2=9\)</span> heads</p></li>
</ul>
<p>Our goal is to estimate the unknown parameters <span class="math inline">\(\theta_A\)</span> and <span class="math inline">\(\theta_B\)</span> from the observed data, even though we don’t know which coin was used in each trial.</p>
<p>We wish to model the data by specifying a joint distribution <span class="math inline">\(p(x_i, z_i \mid \theta_A, \theta_B)\)</span>. Here, <span class="math inline">\(z_i \in \{0,1\}\)</span> is a binary indicator where <span class="math inline">\(z_i=1\)</span> means coin <span class="math inline">\(A\)</span> was used in trial <span class="math inline">\(i\)</span> and <span class="math inline">\(z_i=0\)</span> means coin <span class="math inline">\(B\)</span> was used. We have <span class="math inline">\(p(z_i=1) = p(z_i=0) = 1/2\)</span>.</p>
<p>Given which coin is used, the number of heads follows a binomial distribution: <span class="math inline">\(x_i \mid z_i=1 \sim B(m_i, \theta_A)\)</span> and <span class="math inline">\(x_i \mid z_i=0 \sim B(m_i, \theta_B)\)</span>.</p>
<p>Note that the <span class="math inline">\(z_i\)</span>’s are <strong>latent random variables</strong>, meaning that they’re hidden/unobserved. This is what will make our estimation problem difficult.</p>
<p>The generative process works as follows: For each trial <span class="math inline">\(i\)</span>, we first choose which coin to use (coin <span class="math inline">\(A\)</span> with probability <span class="math inline">\(1/2\)</span>, coin <span class="math inline">\(B\)</span> with probability <span class="math inline">\(1/2\)</span>). Then, given the chosen coin, we flip it <span class="math inline">\(m_i\)</span> times and observe <span class="math inline">\(x_i\)</span> heads. The challenge is that we observe <span class="math inline">\(x_i\)</span> and <span class="math inline">\(m_i\)</span>, but not which coin was chosen.</p>
<p>We want to find the maximum likelihood estimates of the parameters <span class="math inline">\(\theta_A\)</span> and <span class="math inline">\(\theta_B\)</span>.</p>
<p>If we knew what the <span class="math inline">\(z_i\)</span>’s were, the maximum likelihood problem would be straightforward. Specifically, we could then write down the complete-data log-likelihood as</p>
<p><span class="math display">\[\begin{align*}

\ell(\theta_A, \theta_B) &amp;= \sum_{i=1}^{n} \log p(x_i, z_i \mid \theta_A, \theta_B) \\[5pt]

&amp;= \sum_{i=1}^{n} \log p(x_i \mid z_i; \theta_A, \theta_B) + \log p(z_i).

\end{align*}\]</span></p>
<p>Maximizing this with respect to <span class="math inline">\(\theta_A\)</span> and <span class="math inline">\(\theta_B\)</span> gives the parameters:</p>
<p><span class="math display">\[\begin{align*}

\theta_A &amp;= \frac{\sum_{i=1}^{n} z_i \, x_i}{\sum_{i=1}^{n} z_i \, m_i} \\[5pt]

\theta_B &amp;= \frac{\sum_{i=1}^{n} (1-z_i) \, x_i}{\sum_{i=1}^{n} (1-z_i) \, m_i}

\end{align*}\]</span></p>
<p>These are the maximum likelihood estimates of the parameters of the binomial distributions.</p>
<p>In these formulas, the <span class="math inline">\(z_i\)</span>’s act as indicator variables. To estimate <span class="math inline">\(\theta_A\)</span>, we simply divide the total number of heads from trials where coin <span class="math inline">\(A\)</span> was used by the total number of flips where coin <span class="math inline">\(A\)</span> was used. Similarly, to estimate <span class="math inline">\(\theta_B\)</span>, we divide the total number of heads from trials where coin <span class="math inline">\(B\)</span> was used by the total number of flips where coin <span class="math inline">\(B\)</span> was used.</p>
<p>This is a simple and elegant solution—if only we knew which coin was used in each trial!</p>
</section>
<section id="the-marginalized-log-likelihood" class="level1">
<h1>The Marginalized Log-Likelihood</h1>
<p>However, in our problem, the <span class="math inline">\(z_i\)</span>’s are not known. Since we do not know the <span class="math inline">\(z_i\)</span>’s, we need to marginalize them out to compute the log-likelihood of the observed data:</p>
<p><span class="math display">\[\begin{align*}

\ell(\theta_A, \theta_B) &amp;= \sum_{i=1}^{n} \log p(x_i \mid \theta_A, \theta_B) \\[5pt]

&amp;= \sum_{i=1}^{n} \log \sum_{z_i \in \{0,1\}} p(x_i \mid z_i; \theta_A, \theta_B) \, p(z_i).

\end{align*}\]</span></p>
<p>This log-likelihood involves a sum inside a logarithm, which makes it difficult to maximize directly. If we try to solve for the maximum likelihood estimates of the parameters by setting to zero the derivatives of this formula with respect to the parameters, we’ll find that it is <em>not</em> possible to get a closed-form solution.</p>
<p>This is the fundamental challenge: the complete-data log-likelihood is easy to maximize, but we don’t have complete data. The marginalized log-likelihood is what we actually need to maximize, but it’s mathematically difficult to work with directly.</p>
<p>The <strong>EM algorithm</strong> provides an iterative solution to this problem. It updates our estimates of the parameters with two steps:</p>
<ul>
<li>In the <strong>E-step</strong>, we “guess” the values of the <span class="math inline">\(z_i\)</span>’s based on the observed data and the current parameter estimates.</li>
<li>In the <strong>M-step</strong>, we update the parameter estimates to maximize the log-likelihood of the data given the guessed values of the <span class="math inline">\(z_i\)</span>’s.</li>
</ul>
<p>Since in the M-step we assume that the guesses from the E-step are correct, the maximization becomes easy.</p>
<p>Here’s the algorithm:</p>
<p><strong>Initialize</strong> <span class="math inline">\(\theta_A^{(0)}\)</span> and <span class="math inline">\(\theta_B^{(0)}\)</span> with some initial guesses.</p>
<p><strong>Repeat</strong> until convergence of <span class="math inline">\(\theta_A^{(t)}\)</span> and <span class="math inline">\(\theta_B^{(t)}\)</span>:</p>
<ul>
<li><p><strong>(E-step)</strong> For each trial <span class="math inline">\(i\)</span>, compute <span class="math display">\[\begin{align*}
\gamma_{iA} &amp;= p(z_i=1 \mid x_i; \theta_A^{(t)}, \theta_B^{(t)}) \\
\gamma_{iB} &amp;= p(z_i=0 \mid x_i; \theta_A^{(t)}, \theta_B^{(t)}) = 1 - \gamma_{iA}
\end{align*}\]</span></p></li>
<li><p><strong>(M-step)</strong> Update the parameters: <span class="math display">\[\begin{align*}
\theta_A^{(t+1)} &amp;:= \frac{\sum_{i=1}^{n} \gamma_{iA} \, x_i}{\sum_{i=1}^{n} \gamma_{iA} \, m_i} \\[5pt]
\theta_B^{(t+1)} &amp;:= \frac{\sum_{i=1}^{n} \gamma_{iB} \, x_i}{\sum_{i=1}^{n} \gamma_{iB} \, m_i}
\end{align*}\]</span></p></li>
</ul>
<p>In the E-step, we calculate the posterior probability of the <span class="math inline">\(z_i\)</span>’s given the <span class="math inline">\(x_i\)</span>’s and the current parameter estimates. We can find this from the prior probabilities <span class="math inline">\(p(z_i=1)\)</span> and <span class="math inline">\(p(z_i=0)\)</span> and the conditional probabilities <span class="math inline">\(p(x_i \mid z_i=1; \theta_A^{(t)})\)</span> and <span class="math inline">\(p(x_i \mid z_i=0; \theta_B^{(t)})\)</span> using Bayes’ rule.</p>
<p>Notice the similarity between the updates in the M-step and the formulas we had when the <span class="math inline">\(z_i\)</span>’s were known exactly. They are identical, except that instead of the “hard” indicator functions <span class="math inline">\(z_i\)</span> and <span class="math inline">\((1-z_i)\)</span> indicating which coin was used for each trial, we now have the “soft” <strong>responsibilities</strong> <span class="math inline">\(\gamma_{iA}\)</span> and <span class="math inline">\(\gamma_{iB}\)</span> that indicate the probability that coin <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> was used for each trial.</p>
</section>
<section id="why-the-em-algorithm-works" class="level1">
<h1>Why The EM Algorithm Works</h1>
<p>Suppose we have an estimation problem in which we have some data <span class="math inline">\(x\)</span> and we wish to fit a model with parameters <span class="math inline">\(\theta\)</span> by maximizing the log-likelihood of the data, defined as</p>
<p><span class="math display">\[
\ell(\theta)=\log p(x \mid \theta).
\]</span></p>
<p>Suppose we have an unknown latent variable <span class="math inline">\(z\)</span> (which for simplicity we assume takes a finite number of values). We can obtain the density for <span class="math inline">\(x\)</span> by marginalizing over the latent variable <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[
\log p(x \mid \theta)=\log \sum_{z} p(x, z \mid \theta)
\]</span></p>
<p>In such a setting, the EM algorithm gives an efficient method for maximum likelihood estimation. Maximizing <span class="math inline">\(\ell(\theta)\)</span> explicitly might be difficult, and our strategy will be to instead repeatedly construct a lower-bound on <span class="math inline">\(\ell\)</span> (E-step), and then optimize that lower-bound (M-step).</p>
<p>Let <span class="math inline">\(Q\)</span> be some arbitrary probability distribution over the possible values of <span class="math inline">\(z\)</span>. That is, <span class="math inline">\(\sum_{z} Q(z)=1\)</span> and <span class="math inline">\(Q(z) \geq 0\)</span>.</p>
<p>Now, consider the following:</p>
<p><span class="math display">\[\begin{align*}
\log p(x \mid \theta) &amp;= \log \sum_{z} p(x, z \mid \theta) \\[5pt]
&amp;= \log \sum_{z} Q(z) \frac{p(x, z \mid \theta)}{Q(z)} \\[5pt]
&amp;\geq \sum_{z} Q(z) \log \frac{p(x, z \mid \theta)}{Q(z)}
\end{align*}\]</span></p>
<p>In the last step, we used Jensen’s inequality to obtain a lower-bound on <span class="math inline">\(\log p(x \mid \theta)\)</span>. We won’t discuss the proof here, but the inequality above is true for <em>any</em> valid probability distribution <span class="math inline">\(Q\)</span>.</p>
<p>(By valid, we mean that we only consider probability distributions <span class="math inline">\(Q\)</span> that satisfy <span class="math inline">\(p(x, z \mid \theta) &gt; 0 \implies Q(z) &gt; 0\)</span> so that we aren’t dividing by zero.)</p>
<p>We call the expression <span class="math display">\[\sum_{z} Q(z) \log \dfrac{p(x, z \mid \theta)}{Q(z)}\]</span> the <strong>evidence lower bound (ELBO)</strong> and denote it by <span class="math inline">\(\operatorname{ELBO}(x; Q, \theta).\)</span></p>
<p>With this notation, we can write:</p>
<p><span class="math display">\[
\log p(x \mid \theta) \geq \operatorname{ELBO}(x; Q, \theta)
\]</span></p>
<p>for any probability distribution <span class="math inline">\(Q\)</span> and any value of <span class="math inline">\(\theta\)</span>.</p>
<p>Now that we have a lower-bound on <span class="math inline">\(\log p(x \mid \theta)\)</span>, we can use it to optimize <span class="math inline">\(\ell(\theta)\)</span> by adjusting <span class="math inline">\(Q\)</span> and <span class="math inline">\(\theta\)</span>.</p>
<p>If we have some current guess <span class="math inline">\(\theta\)</span>, we should try to make the lower-bound tight at that value of <span class="math inline">\(\theta\)</span>. In other words, we will make the inequality</p>
<p><span class="math display">\[
\log p(x \mid \theta) \geq \operatorname{ELBO}(x; Q, \theta)
\]</span></p>
<p>hold with equality at our particular value of <span class="math inline">\(\theta\)</span>.</p>
<p>To make the bound tight for a particular value of <span class="math inline">\(\theta\)</span>, we need the step involving Jensen’s inequality to hold with equality.</p>
<p>It turns out that we can achieve this by requiring that</p>
<p><span class="math display">\[
\frac{p(x, z \mid \theta)}{Q(z)}=c
\]</span></p>
<p>for some constant <span class="math inline">\(c\)</span> that does not depend on <span class="math inline">\(z\)</span>.</p>
<p>This means that</p>
<p><span class="math display">\[\begin{align*}
Q(z) &amp;= \frac{p(x, z \mid \theta)}{c} \\[5pt]
&amp;= \frac{p(z \mid x, \theta)\,p(x \mid \theta)}{c}
\end{align*}\]</span></p>
<p>Dropping the terms that do not depend on <span class="math inline">\(z\)</span>, we get</p>
<p><span class="math display">\[
Q(z) \propto p(z \mid x, \theta)
\]</span></p>
<p>Since <span class="math inline">\(Q\)</span> and <span class="math inline">\(p(z \mid x, \theta)\)</span> are both probability distributions, the proportionality constant must be <span class="math inline">\(1\)</span>. Thus, we simply set <span class="math inline">\(Q\)</span> to be the posterior distribution of <span class="math inline">\(z\)</span> given <span class="math inline">\(x\)</span> and the current setting of the parameters <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
Q(z) = p(z \mid x, \theta)
\]</span></p>
<p>We can directly verify that when <span class="math inline">\(Q(z)=p(z \mid x, \theta)\)</span>, the lower bound becomes tight:</p>
<p><span class="math display">\[\begin{align*}
\sum_{z} Q(z) \log \frac{p(x, z \mid \theta)}{Q(z)} &amp;= \sum_{z} p(z \mid x, \theta) \log \frac{p(x, z \mid \theta)}{p(z \mid x, \theta)} \\[5pt]
&amp;= \sum_{z} p(z \mid x, \theta) \log \frac{p(z \mid x, \theta)\, p(x \mid \theta)}{p(z \mid x, \theta)} \\[5pt]
&amp;= \sum_{z} p(z \mid x, \theta) \log p(x \mid \theta) \\[5pt]
&amp;= \log p(x \mid \theta) \sum_{z} p(z \mid x, \theta) \\[5pt]
&amp;= \log p(x \mid \theta)
\end{align*}\]</span></p>
<p>where the last step uses the fact that <span class="math inline">\(\sum_{z} p(z \mid x, \theta)=1\)</span>.</p>
<p>The EM algorithm alternately updates <span class="math inline">\(Q\)</span> and <span class="math inline">\(\theta\)</span> in two steps:</p>
<ol type="1">
<li><p><strong>(E-step)</strong> Set <span class="math inline">\(Q(z) = p(z \mid x, \theta)\)</span> using the current value of <span class="math inline">\(\theta\)</span>, so that <span class="math inline">\(\operatorname{ELBO}(x; Q, \theta) = \log p(x \mid \theta)\)</span>.</p></li>
<li><p><strong>(M-step)</strong> Update <span class="math inline">\(\theta\)</span> by maximizing <span class="math inline">\(\operatorname{ELBO}(x; Q, \theta)\)</span> with respect to <span class="math inline">\(\theta\)</span> while keeping <span class="math inline">\(Q\)</span> fixed.</p></li>
</ol>
<p>More formally, the EM algorithm proceeds as follows:</p>
<p><strong>Initialize</strong> <span class="math inline">\(\theta^{(0)}\)</span> with some initial guess.</p>
<p><strong>Repeat</strong> until convergence:</p>
<ul>
<li><p><strong>(E-step)</strong> For the current parameter <span class="math inline">\(\theta^{(t)}\)</span>, set <span class="math display">\[
Q^{(t)}(z) := p(z \mid x, \theta^{(t)})
\]</span></p></li>
<li><p><strong>(M-step)</strong> Update the parameters: <span class="math display">\[
\theta^{(t+1)} := \arg\max_{\theta} \operatorname{ELBO}(x; Q^{(t)}, \theta)
\]</span></p></li>
</ul>
</section>
<section id="proving-that-the-em-algorithm-increases-the-likelihood" class="level1">
<h1>Proving that the EM algorithm increases the likelihood</h1>
<p>We will now prove that the EM algorithm monotonically improves the log-likelihood. Specifically, we will show that <span class="math inline">\(\ell(\theta^{(t)}) \leq \ell(\theta^{(t+1)})\)</span> for successive iterations.</p>
<p>The key to our proof lies in the choice of <span class="math inline">\(Q\)</span>.</p>
<p>On the iteration where the parameters are <span class="math inline">\(\theta^{(t)}\)</span>, we choose <span class="math inline">\(Q^{(t)}(z) := p(z \mid x, \theta^{(t)})\)</span>. We saw in the previous section that this choice ensures that the lower bound is tight, and hence</p>
<p><span class="math display">\[
\ell(\theta^{(t)}) = \log p(x \mid \theta^{(t)}) = \operatorname{ELBO}(x; Q^{(t)}, \theta^{(t)})
\]</span></p>
<p>The parameters <span class="math inline">\(\theta^{(t+1)}\)</span> are then obtained by maximizing <span class="math inline">\(\operatorname{ELBO}(x; Q^{(t)}, \theta)\)</span> with respect to <span class="math inline">\(\theta\)</span>. Thus,</p>
<p><span class="math display">\[\begin{align*}
\ell(\theta^{(t+1)}) &amp;= \log p(x \mid \theta^{(t+1)}) \\[5pt]
&amp;\geq \operatorname{ELBO}(x; Q^{(t)}, \theta^{(t+1)}) \qquad \text{(lower bound holds for all } Q \text{ and } \theta\text{)} \\[5pt]
&amp;\geq \operatorname{ELBO}(x; Q^{(t)}, \theta^{(t)}) \qquad \text{(} \theta^{(t+1)} \text{ maximizes the ELBO)} \\[5pt]
&amp;= \ell(\theta^{(t)})
\end{align*}\]</span></p>
<p>Hence, EM causes the likelihood to converge monotonically.</p>
<p>Note that while EM will find a local optimum of <span class="math inline">\(\ell(\theta)\)</span>, it doesn’t necessarily find the global optimum.</p>
<p>Now here’s the fun part. I built an interactive visualization that lets you set the original parameters, generate some data, and run the EM algorithm.</p>
<p>Notice that the EM algorithm sometimes does not converge to the actual original parameters, but that’s because the data might just have been more likely under some slightly different parameters that the EM algorithm found.</p>
<p>Notice also the symmetry of the landscape. If you initialize on the other side, you would converge to the flipped parameters, which corresponds to changing the names of the coins, which obviously doesn’t actually change the data. But the important point is that the likelihood landscape has multiple maxima, and you don’t know ahead of time which one EM will converge to.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>